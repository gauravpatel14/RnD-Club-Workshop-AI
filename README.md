# R&D Club AI Workshop: Local LLMs & Advanced RAG

This project was developed during a workshop hosted by the R&D Club. It demonstrates how to run AI models locally and use them to analyze specific documents.

## üåü What was done?
1. **Local AI Deployment**: Used **Ollama** to run models like Llama 3.2 on a private environment instead of relying on external cloud APIs.
2. **Advanced RAG (Retrieval-Augmented Generation)**: Built a system that allows the AI to "read" a PDF (specifically the included paper on the Youth Mental Health Crisis) and answer questions based only on that text.



## üõ†Ô∏è Tools Used
- **Python & LangChain**: For building the AI logic.
- **ChromaDB**: A vector database used to store and search the PDF content.
- **Ollama**: To host the open-source Large Language Model.

## üìÇ Project Files
- `ollama.ipynb`: Setting up the local model and web interface.
- `Advance RAG.ipynb`: The logic for document retrieval and analysis.
- `The_youth_mental_health_crisis_analysis_and_soluti.pdf`: The research paper used as the data source.
